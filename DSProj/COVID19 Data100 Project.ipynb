{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 100 Final Project: COVID 19 Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Import Datasets\n",
    "counties = pd.read_csv('abridged_couties.csv')\n",
    "deaths = pd.read_csv('time_series_covid19_deaths_US.csv')\n",
    "cases = pd.read_csv('time_series_covid19_confirmed_US.csv')\n",
    "states = pd.read_csv('4.18states.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning on COVID Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### States Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data cleaning, a good starting point is to check for null and missing values and interpret what they may mean, before replacing them with any particular value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Province_State           0\n",
       "Country_Region           0\n",
       "Last_Update             83\n",
       "Lat                      5\n",
       "Long_                    5\n",
       "Confirmed                0\n",
       "Deaths                   0\n",
       "Recovered               24\n",
       "Active                   1\n",
       "FIPS                    82\n",
       "Incident_Rate            5\n",
       "People_Tested           84\n",
       "People_Hospitalized     91\n",
       "Mortality_Rate           3\n",
       "UID                      0\n",
       "ISO3                     0\n",
       "Testing_Rate            84\n",
       "Hospitalization_Rate    91\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for how many missing values are in every column\n",
    "states.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing information like People_Hospitalized with zero may not be a great idea since we cannot assume there are no people hospitalized, hence, we can replace these missing values with the mean of that country in which specific state data is missing. We can tackle People_Hospitalized, Testing_Rate, Hospitalization_Rate, People_Tested in this way.\n",
    "\n",
    "The cell below calculates how many of the total values for each country are not missing. If a value turns out to be zero that means all data points in People_Hospitalized is missing for that country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "People_Hospitalized \n",
      " {'US': 49, 'China': 0, 'Canada': 0, 'France': 0, 'United Kingdom': 0, 'Australia': 0, 'Netherlands': 0, 'Denmark': 0}\n",
      "Hospitalization_Rate \n",
      " {'US': 49, 'China': 0, 'Canada': 0, 'France': 0, 'United Kingdom': 0, 'Australia': 0, 'Netherlands': 0, 'Denmark': 0}\n",
      "Testing_Rate \n",
      " {'US': 56, 'China': 0, 'Canada': 0, 'France': 0, 'United Kingdom': 0, 'Australia': 0, 'Netherlands': 0, 'Denmark': 0}\n",
      "People Tested \n",
      " {'US': 56, 'China': 0, 'Canada': 0, 'France': 0, 'United Kingdom': 0, 'Australia': 0, 'Netherlands': 0, 'Denmark': 0}\n",
      "Mortality Rate \n",
      " {'US': 57, 'China': 33, 'Canada': 13, 'France': 10, 'United Kingdom': 10, 'Australia': 8, 'Netherlands': 4, 'Denmark': 2}\n"
     ]
    }
   ],
   "source": [
    "countries = states['Country_Region'].value_counts().index.tolist()\n",
    "people_hospitalization_country_nulls = {}\n",
    "def usable_vals(col):\n",
    "    dic = {}\n",
    "    for country in countries:\n",
    "           dic[country] = len(states.loc[states['Country_Region'] == country,col].isnull()) - sum(states.loc[states['Country_Region'] == country,col].isnull())\n",
    "    return dic\n",
    "People_Hospitalization_country_nulls = usable_vals('People_Hospitalized')\n",
    "Hospitalization_Rate_country_nulls = usable_vals('Hospitalization_Rate')\n",
    "print(Hospitalization_Rate_country_nulls == People_Hospitalization_country_nulls)\n",
    "print('People_Hospitalized \\n', usable_vals('People_Hospitalized'))\n",
    "print('Hospitalization_Rate \\n', usable_vals('Hospitalization_Rate'))\n",
    "print('Testing_Rate \\n', usable_vals('Testing_Rate'))\n",
    "print('People Tested \\n', usable_vals('People_Tested'))\n",
    "print('Mortality Rate \\n', usable_vals('Mortality_Rate'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that there is another null value in a country outside the US, so to see which country that is, we can instead of check the values that are not null to sum the values that are infact null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'US': 0,\n",
       " 'China': 0,\n",
       " 'Canada': 0,\n",
       " 'France': 0,\n",
       " 'United Kingdom': 0,\n",
       " 'Australia': 0,\n",
       " 'Netherlands': 0,\n",
       " 'Denmark': 0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mortality_dic = {}\n",
    "for country in countries:\n",
    "        mortality_dic[country] =  sum(states.loc[states['Country_Region'] == country,'Mortality_Rate'].isnull())\n",
    "mortality_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the data for US contains values that will be usable so we can go ahead and replace the NaN values in the US data with the mean of that column in the US and from here note that we can only incorporate People_Hospitalized in analysis within the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Last_Update</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Active</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Incident_Rate</th>\n",
       "      <th>People_Tested</th>\n",
       "      <th>People_Hospitalized</th>\n",
       "      <th>Mortality_Rate</th>\n",
       "      <th>UID</th>\n",
       "      <th>ISO3</th>\n",
       "      <th>Testing_Rate</th>\n",
       "      <th>Hospitalization_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-04-18 22:32:47</td>\n",
       "      <td>32.3182</td>\n",
       "      <td>-86.9023</td>\n",
       "      <td>4712</td>\n",
       "      <td>153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4559.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.492717</td>\n",
       "      <td>42538.0</td>\n",
       "      <td>620.000000</td>\n",
       "      <td>3.247029</td>\n",
       "      <td>84000001</td>\n",
       "      <td>USA</td>\n",
       "      <td>907.206961</td>\n",
       "      <td>13.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-04-18 22:32:47</td>\n",
       "      <td>61.3707</td>\n",
       "      <td>-152.4044</td>\n",
       "      <td>314</td>\n",
       "      <td>9</td>\n",
       "      <td>147.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.530410</td>\n",
       "      <td>9655.0</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>2.866242</td>\n",
       "      <td>84000002</td>\n",
       "      <td>USA</td>\n",
       "      <td>1615.226458</td>\n",
       "      <td>12.420382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.2710</td>\n",
       "      <td>-170.1320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2327.122449</td>\n",
       "      <td>3.727277</td>\n",
       "      <td>16</td>\n",
       "      <td>ASM</td>\n",
       "      <td>5.391708</td>\n",
       "      <td>14.141068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-04-18 22:32:47</td>\n",
       "      <td>33.7298</td>\n",
       "      <td>-111.4312</td>\n",
       "      <td>4724</td>\n",
       "      <td>180</td>\n",
       "      <td>539.0</td>\n",
       "      <td>4544.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.901548</td>\n",
       "      <td>51045.0</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>3.810330</td>\n",
       "      <td>84000004</td>\n",
       "      <td>USA</td>\n",
       "      <td>701.291175</td>\n",
       "      <td>11.981372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-04-18 22:32:47</td>\n",
       "      <td>34.9697</td>\n",
       "      <td>-92.3731</td>\n",
       "      <td>1744</td>\n",
       "      <td>38</td>\n",
       "      <td>703.0</td>\n",
       "      <td>1706.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>67.361213</td>\n",
       "      <td>24141.0</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>2.178899</td>\n",
       "      <td>84000005</td>\n",
       "      <td>USA</td>\n",
       "      <td>932.435235</td>\n",
       "      <td>16.685780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Province_State Country_Region          Last_Update      Lat     Long_  \\\n",
       "0         Alabama             US  2020-04-18 22:32:47  32.3182  -86.9023   \n",
       "1          Alaska             US  2020-04-18 22:32:47  61.3707 -152.4044   \n",
       "2  American Samoa             US                  NaN -14.2710 -170.1320   \n",
       "3         Arizona             US  2020-04-18 22:32:47  33.7298 -111.4312   \n",
       "4        Arkansas             US  2020-04-18 22:32:47  34.9697  -92.3731   \n",
       "\n",
       "   Confirmed  Deaths  Recovered  Active  FIPS  Incident_Rate  People_Tested  \\\n",
       "0       4712     153        NaN  4559.0   1.0     100.492717        42538.0   \n",
       "1        314       9      147.0   305.0   2.0      52.530410         9655.0   \n",
       "2          0       0        NaN     NaN  60.0       0.000000            3.0   \n",
       "3       4724     180      539.0  4544.0   4.0      64.901548        51045.0   \n",
       "4       1744      38      703.0  1706.0   5.0      67.361213        24141.0   \n",
       "\n",
       "   People_Hospitalized  Mortality_Rate       UID ISO3  Testing_Rate  \\\n",
       "0           620.000000        3.247029  84000001  USA    907.206961   \n",
       "1            39.000000        2.866242  84000002  USA   1615.226458   \n",
       "2          2327.122449        3.727277        16  ASM      5.391708   \n",
       "3           566.000000        3.810330  84000004  USA    701.291175   \n",
       "4           291.000000        2.178899  84000005  USA    932.435235   \n",
       "\n",
       "   Hospitalization_Rate  \n",
       "0             13.157895  \n",
       "1             12.420382  \n",
       "2             14.141068  \n",
       "3             11.981372  \n",
       "4             16.685780  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_nan_with_mean(country, col):\n",
    "    arr = states.loc[states['Country_Region'] == country, col]\n",
    "    arr_mean = arr.mean()\n",
    "    arr.fillna(arr_mean, inplace=True)\n",
    "    states.loc[states['Country_Region'] == country,col] = arr\n",
    "\n",
    "replace_nan_with_mean('US','People_Hospitalized')\n",
    "replace_nan_with_mean('US','Hospitalization_Rate')\n",
    "replace_nan_with_mean('US','Testing_Rate')\n",
    "replace_nan_with_mean('US','People_Tested')\n",
    "replace_nan_with_mean('US','Mortality_Rate')\n",
    "\n",
    "# There is still an uncovered NaN value in Mortality_Rate but this time in a different country so we can remove that. Namely, Canada.\n",
    "replace_nan_with_mean('Canada','Mortality_Rate')\n",
    "\n",
    "states.isnull().sum()\n",
    "states.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cases and Deaths DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we clean the dataframes of cases and deaths. After examining the data, we first drop the rows with out of state FIPS, unassigned FIPS, correctional facilities and the Grand Princess. Then we fill in or appropriately reassign rows with missing FIPS, using data from census.gov. Next, we merge to create a dataframe containing total confirmed cases and deaths by region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushsehgal/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>total_confirmed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>mortality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>32.539527</td>\n",
       "      <td>-86.644082</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01003</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>30.727750</td>\n",
       "      <td>-87.722071</td>\n",
       "      <td>109</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01005</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>31.868263</td>\n",
       "      <td>-85.387129</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01007</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>32.996421</td>\n",
       "      <td>-87.125115</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01009</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>33.982109</td>\n",
       "      <td>-86.567906</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FIPS Province_State        Lat       Long  total_confirmed  total_deaths  \\\n",
       "5  01001        Alabama  32.539527 -86.644082               25             2   \n",
       "6  01003        Alabama  30.727750 -87.722071              109             2   \n",
       "7  01005        Alabama  31.868263 -85.387129               18             0   \n",
       "8  01007        Alabama  32.996421 -87.125115               26             0   \n",
       "9  01009        Alabama  33.982109 -86.567906               20             0   \n",
       "\n",
       "   mortality  \n",
       "5   0.080000  \n",
       "6   0.018349  \n",
       "7   0.000000  \n",
       "8   0.000000  \n",
       "9   0.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping out of state FIPS, unassigned FIPS, correctional facilities and the Grand Princess\n",
    "cases.drop(cases.index[3149:3255], inplace = True)\n",
    "deaths.drop(deaths.index[3149:3255], inplace = True)\n",
    "\n",
    "# Replace missing FIPS for Kansas City with data from census.gov\n",
    "cases.loc[cases['Admin2']=='Kansas City', 'FIPS'] = 29380.0\n",
    "deaths.loc[deaths['Admin2']=='Kansas City', 'FIPS'] = 29380.0\n",
    "\n",
    "# Duke and Nantucket Counties' numbers have been counted jointly, recorded only under 'Dukes and Nantucket'. Ideally, the counts would be redistributed evenly between Duke and Nantucket, however it is not realistic to assign 0.5 deaths to a county. Therefore, we have assigned all counts to the FIPS of Nantucket and dropped the Nantucket row. This is not an ideal solution.\n",
    "cases.loc[cases['Admin2']=='Dukes and Nantucket', 'FIPS'] = 25019.0\n",
    "deaths.loc[deaths['Admin2']=='Dukes and Nantucket', 'FIPS'] = 25019.0\n",
    "cases.drop(cases.loc[cases['Admin2']=='Nantucket',:].index, inplace = True)\n",
    "deaths.drop(deaths.loc[deaths['Admin2']=='Nantucket',:].index, inplace = True)\n",
    "#deaths[deaths['FIPS'].isnull()]\n",
    "\n",
    "# Convert to string and add padded 0 for consistency with counties data\n",
    "deaths['FIPS'] = deaths['FIPS'].astype(int).astype(str).str.zfill(5)\n",
    "cases['FIPS'] = cases['FIPS'].astype(int).astype(str).str.zfill(5)\n",
    "\n",
    "# Create a dataframe with the total confirmed cases and deaths by region.\n",
    "total_cases = cases[['FIPS', 'Province_State', 'Lat', 'Long_', '4/18/20']]\n",
    "total_cases.rename(columns={'4/18/20':'total_confirmed'}, inplace=True)\n",
    "total_deaths = deaths[['FIPS', '4/18/20']]\n",
    "total_deaths.rename(columns={'4/18/20':'total_deaths'}, inplace=True)\n",
    "total_by_region = total_cases.merge(total_deaths, how = 'left', on = ['FIPS'])\n",
    "total_by_region.rename(columns={'Long_':'Long'}, inplace = True)\n",
    "total_by_region.head(10)\n",
    "\n",
    "# Dropping America Samoa, Guam, Northern Mariana Islands, Puerto Rico and Virgin Islands\n",
    "total_by_region.drop(total_by_region.index[0:5], inplace = True)\n",
    "\n",
    "# Adding a column with mortality rate\n",
    "total_by_region['mortality'] = total_by_region['total_deaths'] / total_by_region['total_confirmed']\n",
    "total_by_region['mortality'] = np.nan_to_num(total_by_region['mortality'])\n",
    "total_by_region.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### County DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at the features of counties alongside confirmed cases and death counts, we merge the dataframes. We then examine the null values and implement appropriate cleaning. We focus our data explanation on features which may affect the mortality rates of states and countries. \n",
    "\n",
    "We drop the 3 rows (FIPS 02158 in Alaska, FIPS 46102 in South Dakota, and FIPS 29380 in Missouri) that have multiple null values. Although 29380 in Missouri had 412 Covid cases, we decide to drop these 3 columns as we do not have a reliable method of filling in the missing values. We then drop the columns that do not pertain to our study of mortality rates or that have so many null values that they are rendered unreliable. Counties belonging to North and South Dakota had null values for '>50 gatherings', '>500 gatherings', 'stay at home', and 'entertainment/gym'. After consulting outside sources (NPR), we discovered this was because these states did not institute such bans and filled the values with zero. Lastly, there we filled the null values in columns 'HeartDiseaseMortality', 'StrokeMortality', and 'SVIPercentile' with the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FIPS', 'Province_State', 'Lat', 'Long', 'total_confirmed', 'total_deaths', 'mortality', 'CountyName', 'PopulationEstimate2018', 'PopTotalMale2017', 'PopTotalFemale2017', 'PopulationEstimate65+2017', 'PopulationDensityperSqMile2010', 'CensusPopulation2010', 'MedianAge2010', 'DiabetesPercentage', 'HeartDiseaseMortality', 'StrokeMortality', 'Smokers_Percentage', 'RespMortalityRate2014', '#FTEHospitalTotal2017', \"TotalM.D.'s,TotNon-FedandFed2017\", '#HospParticipatinginNetwork2017', '#Hospitals', '#ICU_beds', 'stay at home', '>50 gatherings', '>500 gatherings', 'public schools', 'restaurant dine-in', 'entertainment/gym', 'SVIPercentile']\n"
     ]
    }
   ],
   "source": [
    "county_cases = total_by_region.merge(counties, how = 'left', left_on = 'FIPS', right_on = 'countyFIPS')\n",
    "\n",
    "# There are 3 rows (FIPS 02158 in Alaska, FIPS 46102 in South Dakota, and FIPS 29380 in Missouri) that have multiple null values. Although 29380 in Missouri had 412 Covid cases, we decide to drop these 3 columns as we do not have a reliable method of filling in the missing values.\n",
    "county_cases.drop(county_cases[county_cases['countyFIPS'].isnull()].index, inplace = True)\n",
    "\n",
    "# We drop the columns that are either not of interest to our study or that have too many null values to be useful or reliable. We also drop redundant identifiers (ie countyFIPS and COUNTYFP).\n",
    "county_cases.drop(['dem_to_rep_ratio', 'PopMale<52010', 'PopFmle<52010', 'PopMale5-92010', 'PopFmle5-92010', 'PopMale10-142010', 'PopFmle10-142010', 'PopMale15-192010','PopFmle15-192010', 'PopMale20-242010', 'PopFmle20-242010', 'PopMale25-292010', 'PopFmle25-292010', 'PopMale30-342010', 'PopFmle30-342010', 'PopMale35-442010', 'PopFmle35-442010', 'PopMale45-542010', 'PopFmle45-542010', 'PopMale55-592010', 'PopFmle55-592010', 'PopMale60-642010', 'PopFmle60-642010', 'PopMale65-742010', 'PopFmle65-742010', 'PopMale75-842010', 'PopFmle75-842010', 'PopMale>842010', 'PopFmle>842010', 'CensusRegionName', 'CensusDivisionName', 'Rural-UrbanContinuumCode2013', 'FracMale2017', '3-YrMortalityAge<1Year2015-17', '3-YrMortalityAge1-4Years2015-17', '3-YrMortalityAge5-14Years2015-17', '3-YrMortalityAge15-24Years2015-17', '3-YrMortalityAge25-34Years2015-17', '3-YrMortalityAge35-44Years2015-17', '3-YrMortalityAge45-54Years2015-17', '3-YrMortalityAge55-64Years2015-17', '3-YrMortalityAge65-74Years2015-17', '3-YrMortalityAge75-84Years2015-17', '3-YrMortalityAge85+Years2015-17', 'mortality2015-17Estimated', 'HPSAShortage', 'HPSAServedPop', 'HPSAUnderservedPop', '3-YrDiabetes2015-17', 'MedicareEnrollment,AgedTot2017', '#EligibleforMedicare2018', 'federal guidelines', 'foreign travel ban', 'countyFIPS', 'COUNTYFP', 'STATEFP', 'StateName', 'State', 'lat', 'lon', 'POP_LATITUDE', 'POP_LONGITUDE' ], axis = 1, inplace = True)\n",
    "\n",
    "#The counties with null values for the date of certain bans did not institute such bans, so we filled those values with 0. (https://www.npr.org/2020/05/01/847413697/midwest-coronavirus-related-restrictions-by-state)\n",
    "county_cases = county_cases.fillna({'>50 gatherings':0, '>500 gatherings':0, 'stay at home':0, 'entertainment/gym':0})\n",
    "\n",
    "#Lastly, there are 3 columns with null values that are most appropriately accounted for by filling with mean.\n",
    "county_cases['HeartDiseaseMortality'].fillna(county_cases['HeartDiseaseMortality'].mean(), inplace = True)\n",
    "county_cases['StrokeMortality'].fillna(county_cases['StrokeMortality'].mean(), inplace = True)\n",
    "county_cases['SVIPercentile'].fillna(county_cases['StrokeMortality'].mean(), inplace = True)\n",
    "\n",
    "# This prints the number of null values in each column.\n",
    "# print('Null values in county_cases:\\n')\n",
    "# for column in county_cases.columns.values.tolist():\n",
    "#     print(column,':', sum(county_cases[column].isnull()) )\n",
    "\n",
    "#'DiabetesPercentage', 'HeartDiseaseMortality', 'StrokeMortality', 'Smokers_Percentage', 'RespMortalityRate2014'\n",
    "print(list(county_cases.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total cases in California and New York:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_cases = county_cases.loc[county_cases['Province_State'] == 'California']\n",
    "ny_cases = county_cases.loc[county_cases['Province_State'] == 'New York']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns within counties have been inputted as Gregorian ordinal, which can be converted to the more readible and comprehensible MM/DD/YYYY ISO format built into pandas. The following columns need this change: stay at home, >50 gatherings, >500 gatherings, public schools, restaurant dine-in, entertainment/gym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "cols = ['stay at home','>50 gatherings','>500 gatherings','public schools','restaurant dine-in','entertainment/gym']\n",
    "def date_change(df,cols):\n",
    "    for col in cols:\n",
    "        state_dates = df[col].unique()\n",
    "        for dates in state_dates:\n",
    "            new_state_date = date.fromordinal(int(dates)).isoformat()\n",
    "            df[col].replace(dates, new_state_date, inplace=True)\n",
    "date_change(ca_cases, cols)\n",
    "date_change(ny_cases, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we group the county data by State to create a dataframe with the data available at the county level extended to the state level. Then we merge with the cleaned States dataframe to have the information on state level mortality, hospitalization and testing alongside information about the measures the state took and information about the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>PopulationDensityperSqMile2010</th>\n",
       "      <th>MedianAge2010</th>\n",
       "      <th>DiabetesPercentage</th>\n",
       "      <th>HeartDiseaseMortality</th>\n",
       "      <th>StrokeMortality</th>\n",
       "      <th>Smokers_Percentage</th>\n",
       "      <th>RespMortalityRate2014</th>\n",
       "      <th>stay at home</th>\n",
       "      <th>&gt;50 gatherings</th>\n",
       "      <th>...</th>\n",
       "      <th>Active</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Incident_Rate</th>\n",
       "      <th>People_Tested</th>\n",
       "      <th>People_Hospitalized</th>\n",
       "      <th>Mortality_Rate</th>\n",
       "      <th>UID</th>\n",
       "      <th>ISO3</th>\n",
       "      <th>Testing_Rate</th>\n",
       "      <th>Hospitalization_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>90.216418</td>\n",
       "      <td>39.356716</td>\n",
       "      <td>14.407463</td>\n",
       "      <td>243.595522</td>\n",
       "      <td>51.450746</td>\n",
       "      <td>19.989231</td>\n",
       "      <td>77.282985</td>\n",
       "      <td>737518.865672</td>\n",
       "      <td>737504.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4559.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.492717</td>\n",
       "      <td>42538.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.247029</td>\n",
       "      <td>84000001</td>\n",
       "      <td>USA</td>\n",
       "      <td>907.206961</td>\n",
       "      <td>13.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>8.010714</td>\n",
       "      <td>37.228571</td>\n",
       "      <td>8.667857</td>\n",
       "      <td>165.294140</td>\n",
       "      <td>37.801941</td>\n",
       "      <td>20.085217</td>\n",
       "      <td>54.682500</td>\n",
       "      <td>737511.785714</td>\n",
       "      <td>737507.928571</td>\n",
       "      <td>...</td>\n",
       "      <td>305.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.530410</td>\n",
       "      <td>9655.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.866242</td>\n",
       "      <td>84000002</td>\n",
       "      <td>USA</td>\n",
       "      <td>1615.226458</td>\n",
       "      <td>12.420382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>52.046667</td>\n",
       "      <td>38.653333</td>\n",
       "      <td>10.060000</td>\n",
       "      <td>148.826667</td>\n",
       "      <td>30.900000</td>\n",
       "      <td>16.483911</td>\n",
       "      <td>51.968667</td>\n",
       "      <td>737515.000000</td>\n",
       "      <td>737501.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4544.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.901548</td>\n",
       "      <td>51045.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>3.810330</td>\n",
       "      <td>84000004</td>\n",
       "      <td>USA</td>\n",
       "      <td>701.291175</td>\n",
       "      <td>11.981372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>54.357333</td>\n",
       "      <td>40.316000</td>\n",
       "      <td>13.432000</td>\n",
       "      <td>235.172000</td>\n",
       "      <td>47.681333</td>\n",
       "      <td>20.388849</td>\n",
       "      <td>72.727067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>737510.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1706.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>67.361213</td>\n",
       "      <td>24141.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>2.178899</td>\n",
       "      <td>84000005</td>\n",
       "      <td>USA</td>\n",
       "      <td>932.435235</td>\n",
       "      <td>16.685780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>663.255172</td>\n",
       "      <td>38.503448</td>\n",
       "      <td>8.505172</td>\n",
       "      <td>153.908621</td>\n",
       "      <td>37.891379</td>\n",
       "      <td>12.091600</td>\n",
       "      <td>52.153621</td>\n",
       "      <td>737503.000000</td>\n",
       "      <td>737503.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>29351.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>77.766063</td>\n",
       "      <td>251614.0</td>\n",
       "      <td>4892.0</td>\n",
       "      <td>3.738808</td>\n",
       "      <td>84000006</td>\n",
       "      <td>USA</td>\n",
       "      <td>641.731334</td>\n",
       "      <td>16.044079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State  PopulationDensityperSqMile2010  MedianAge2010  \\\n",
       "0        Alabama                       90.216418      39.356716   \n",
       "1         Alaska                        8.010714      37.228571   \n",
       "2        Arizona                       52.046667      38.653333   \n",
       "3       Arkansas                       54.357333      40.316000   \n",
       "4     California                      663.255172      38.503448   \n",
       "\n",
       "   DiabetesPercentage  HeartDiseaseMortality  StrokeMortality  \\\n",
       "0           14.407463             243.595522        51.450746   \n",
       "1            8.667857             165.294140        37.801941   \n",
       "2           10.060000             148.826667        30.900000   \n",
       "3           13.432000             235.172000        47.681333   \n",
       "4            8.505172             153.908621        37.891379   \n",
       "\n",
       "   Smokers_Percentage  RespMortalityRate2014   stay at home  >50 gatherings  \\\n",
       "0           19.989231              77.282985  737518.865672   737504.000000   \n",
       "1           20.085217              54.682500  737511.785714   737507.928571   \n",
       "2           16.483911              51.968667  737515.000000   737501.000000   \n",
       "3           20.388849              72.727067       0.000000   737510.000000   \n",
       "4           12.091600              52.153621  737503.000000   737503.000000   \n",
       "\n",
       "   ...   Active  FIPS  Incident_Rate  People_Tested  People_Hospitalized  \\\n",
       "0  ...   4559.0   1.0     100.492717        42538.0                620.0   \n",
       "1  ...    305.0   2.0      52.530410         9655.0                 39.0   \n",
       "2  ...   4544.0   4.0      64.901548        51045.0                566.0   \n",
       "3  ...   1706.0   5.0      67.361213        24141.0                291.0   \n",
       "4  ...  29351.0   6.0      77.766063       251614.0               4892.0   \n",
       "\n",
       "   Mortality_Rate       UID  ISO3  Testing_Rate  Hospitalization_Rate  \n",
       "0        3.247029  84000001   USA    907.206961             13.157895  \n",
       "1        2.866242  84000002   USA   1615.226458             12.420382  \n",
       "2        3.810330  84000004   USA    701.291175             11.981372  \n",
       "3        2.178899  84000005   USA    932.435235             16.685780  \n",
       "4        3.738808  84000006   USA    641.731334             16.044079  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Morgan's note to self: I realized that we don't necessarily know if the numbers (death, cases, mortality) in the counties dataframe are actually the same as what was reported in the states dataframe...Say if we train a model on counties data then apply it to states data and these numbers are different, it could be problematic. MUST EXPLORE!\n",
    "# First we aggregate the county infomration by state.\n",
    "state_cases_sum = county_cases[['Province_State','total_confirmed', 'total_deaths','PopulationEstimate2018', 'PopTotalMale2017', 'PopTotalFemale2017', 'PopulationEstimate65+2017',         'CensusPopulation2010', '#FTEHospitalTotal2017', \"TotalM.D.'s,TotNon-FedandFed2017\", '#HospParticipatinginNetwork2017', '#Hospitals', '#ICU_beds']].groupby(['Province_State']).sum().reset_index()\n",
    "\n",
    "state_cases_mean = county_cases[['Province_State', 'PopulationDensityperSqMile2010','MedianAge2010', 'DiabetesPercentage', 'HeartDiseaseMortality', 'StrokeMortality', 'Smokers_Percentage', 'RespMortalityRate2014', 'stay at home', '>50 gatherings', '>500 gatherings', 'public schools', 'restaurant dine-in', 'entertainment/gym', 'SVIPercentile']].groupby(['Province_State']).mean().reset_index()\n",
    "\n",
    "state_cases = state_cases_mean.merge(state_cases_sum, how = 'left', on = 'Province_State')\n",
    "\n",
    "# Now we merge with the states dataframe.\n",
    "state_cases = state_cases.merge(states[states['Country_Region'] == 'US'], how = 'left', on = 'Province_State')\n",
    "\n",
    "state_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>1/28/20</th>\n",
       "      <th>1/29/20</th>\n",
       "      <th>1/30/20</th>\n",
       "      <th>1/31/20</th>\n",
       "      <th>...</th>\n",
       "      <th>4/9/20</th>\n",
       "      <th>4/10/20</th>\n",
       "      <th>4/11/20</th>\n",
       "      <th>4/12/20</th>\n",
       "      <th>4/13/20</th>\n",
       "      <th>4/14/20</th>\n",
       "      <th>4/15/20</th>\n",
       "      <th>4/16/20</th>\n",
       "      <th>4/17/20</th>\n",
       "      <th>4/18/20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountyName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Autauga</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baldwin</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>59</td>\n",
       "      <td>66</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>87</td>\n",
       "      <td>91</td>\n",
       "      <td>101</td>\n",
       "      <td>103</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barbour</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bibb</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blount</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1/22/20  1/23/20  1/24/20  1/25/20  1/26/20  1/27/20  1/28/20  \\\n",
       "CountyName                                                                  \n",
       "Autauga           0        0        0        0        0        0        0   \n",
       "Baldwin           0        0        0        0        0        0        0   \n",
       "Barbour           0        0        0        0        0        0        0   \n",
       "Bibb              0        0        0        0        0        0        0   \n",
       "Blount            0        0        0        0        0        0        0   \n",
       "\n",
       "            1/29/20  1/30/20  1/31/20  ...  4/9/20  4/10/20  4/11/20  4/12/20  \\\n",
       "CountyName                             ...                                      \n",
       "Autauga           0        0        0  ...      15       17       19       19   \n",
       "Baldwin           0        0        0  ...      56       59       66       71   \n",
       "Barbour           0        0        0  ...       4        9        9       10   \n",
       "Bibb              0        0        0  ...       9       11       13       16   \n",
       "Blount            0        0        0  ...      11       12       12       13   \n",
       "\n",
       "            4/13/20  4/14/20  4/15/20  4/16/20  4/17/20  4/18/20  \n",
       "CountyName                                                        \n",
       "Autauga          19       23       24       26       26       25  \n",
       "Baldwin          72       87       91      101      103      109  \n",
       "Barbour          10       11       12       14       15       18  \n",
       "Bibb             17       17       18       22       24       26  \n",
       "Blount           14       16       17       18       20       20  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Series data with county info for counties with non-zero cases\n",
    "time_deaths= county_cases[county_cases['total_confirmed'] != 0].merge(deaths.drop(['UID', 'iso2', 'iso3', 'code3', 'Admin2','Province_State', 'Country_Region', 'Lat', 'Long_', 'Combined_Key'], axis =1), how = 'left', on = 'FIPS')\n",
    "time_cases= county_cases[county_cases['total_confirmed'] != 0].merge(cases.drop(['UID', 'iso2', 'iso3', 'code3', 'Admin2','Province_State', 'Country_Region', 'Lat', 'Long_', 'Combined_Key'], axis =1), how = 'left', on = 'FIPS')\n",
    "\n",
    "date_array = ['1/22/20', '1/23/20', '1/24/20', '1/25/20', '1/26/20', '1/27/20', '1/28/20', '1/29/20', '1/30/20', '1/31/20', '2/1/20', '2/2/20', '2/3/20', '2/4/20', '2/5/20', '2/6/20', '2/7/20', '2/8/20', '2/9/20', '2/10/20', '2/11/20', '2/12/20', '2/13/20', '2/14/20', '2/15/20', '2/16/20', '2/17/20', '2/18/20', '2/19/20', '2/20/20', '2/21/20', '2/22/20', '2/23/20', '2/24/20', '2/25/20', '2/26/20', '2/27/20', '2/28/20', '2/29/20', '3/1/20', '3/2/20', '3/3/20', '3/4/20', '3/5/20', '3/6/20', '3/7/20', '3/8/20', '3/9/20', '3/10/20', '3/11/20', '3/12/20', '3/13/20', '3/14/20', '3/15/20', '3/16/20', '3/17/20', '3/18/20', '3/19/20', '3/20/20', '3/21/20', '3/22/20', '3/23/20', '3/24/20', '3/25/20', '3/26/20', '3/27/20', '3/28/20', '3/29/20', '3/30/20', '3/31/20', '4/1/20', '4/2/20', '4/3/20', '4/4/20', '4/5/20', '4/6/20', '4/7/20', '4/8/20', '4/9/20', '4/10/20', '4/11/20', '4/12/20', '4/13/20', '4/14/20', '4/15/20', '4/16/20', '4/17/20', '4/18/20']\n",
    "plot_cases = time_cases.set_index('CountyName')[date_array] \n",
    "plot_cases.head()\n",
    "#print(list(time_cases.columns))\n",
    "# ca = county_cases.loc[county_cases['Province_State'] == 'California']\n",
    "# sns.scatterplot(x='RespMortalityRate2014',y='total_deaths',data=county_cases)\n",
    "#sns.scatterplot(x='PopulationDensityperSqMile2010',y='total_deaths',data=county_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Level Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our exploration can be on the Mortality Rate. We want to explore what are the features specifically of states that lead to the given mortality rate. As we saw above, there is a lot of missing data in terms of hospitalization in countries other than the US (which could be a helpful metric later on), so we can focus on the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# US_States = states[states['Country_Region'] == 'US']\n",
    "# US_States.drop(116, axis=0,inplace=True)\n",
    "# US_States.drop(['Recovered','Active','FIPS','ISO3','Last_Update','Country_Region'],axis=1,inplace=True)\n",
    "# US_states = states[['Province_State','Mortality_Rate']]\n",
    "\n",
    "# fp = './DSProj/img/states.shp'\n",
    "# US_Map = gpd.read_file(fp)\n",
    "# US_Map = US_Map.rename(columns={'STATE_NAME':'Province_State'})\n",
    "# merged = US_Map.merge(US_states, on='Province_State')\n",
    "# rate_min = merged['Mortality_Rate'].min()\n",
    "# rate_max = merged['Mortality_Rate'].max()\n",
    "\n",
    "# metric = 'Mortality_Rate'\n",
    "# fig, ax = plt.subplots(figsize = (10,6))\n",
    "# merged.plot(column=metric,cmap='BuGn',linewidth=0.8,ax=ax,edgecolor='0.8')\n",
    "# sm = plt.cm.ScalarMappable(cmap='BuGn', norm=plt.Normalize(vmin=rate_min, vmax=rate_max))\n",
    "# sm._A = []\n",
    "# cbar = fig.colorbar(sm, label='Mortality Rate (%)')\n",
    "# # fig.savefig(map_export.png’, dpi=300)\n",
    "# plt.title('Mortality Rate in US States')\n",
    "# plt.xlabel('Longitude')\n",
    "# plt.ylabel('Latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis: we can consider the data we have for the counties and group them as follows: \n",
    "1. ***Population* Stats**:  'PopulationEstimate2018',  'PopTotalMale2017',  'PopTotalFemale2017',  'PopulationEstimate65+2017',  'PopulationDensityperSqMile2010',  'CensusPopulation2010',\n",
    "2. **At *Risk* Populations**:  'MedianAge2010',  'DiabetesPercentage',  'HeartDiseaseMortality',  'StrokeMortality',  'Smokers_Percentage', 'RespMortalityRate2014',\n",
    "3. ***Infrastructure* (Ability to provide care)**:  '#FTEHospitalTotal2017', \"TotalM.D.'s,TotNon-FedandFed2017\", '#HospParticipatinginNetwork2017', '#Hospitals', '#ICU_beds', 'SVIPercentile'\n",
    "4. **Pandemic *Policies* Enacted**: 'stay at home', '>50 gatherings', '>500 gatherings', 'public schools', 'restaurant dine-in', 'entertainment/gym'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_stats = ['PopulationEstimate2018', 'PopTotalMale2017', 'PopTotalFemale2017', 'PopulationEstimate65+2017', 'PopulationDensityperSqMile2010', 'CensusPopulation2010','mortality']\n",
    "\n",
    "def select_columns(data, columns): \n",
    "    return data.loc[:,columns]\n",
    "\n",
    "def process_data(data, metric):\n",
    "    \n",
    "    # Select the desired columns \n",
    "    df = select_columns(data, population_stats)\n",
    "    \n",
    "    # Return features matrix and response variable (X and Y)\n",
    "    X = df.drop([metric], axis=1)\n",
    "    Y = df.loc[:,metric]\n",
    "    \n",
    "    return X,Y\n",
    "X_ca_pop, Y_ca_pop = process_data(ca_cases,'mortality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
