{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 100 Final Project: COVID 19 Dataset\n",
    "Collaborators:\n",
    "\n",
    "1. Exploratory Data Analysis\n",
    "\n",
    "Import, clean, and merge dataframes\n",
    "\n",
    "Examine County features (which ones?) in relation to death/confirmed/mortality/rate of spread\n",
    "\n",
    "Produce 2 visualizations\n",
    "\n",
    "Assignments:\n",
    "\n",
    "?: Clean states dataframe, ...\n",
    "\n",
    "Morgan: Import, clean, merge and examine features for California\n",
    "\n",
    "?: Import, clean, merge and examine features for New York\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Import Datasets\n",
    "counties = pd.read_csv('abridged_couties.csv')\n",
    "deaths = pd.read_csv('time_series_covid19_deaths_US.csv')\n",
    "cases = pd.read_csv('time_series_covid19_confirmed_US.csv')\n",
    "states = pd.read_csv('4.18states.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Describe any data cleaning or transformations that you perform and why they are motivated by your EDA.\n",
    "\n",
    "3. Apply relevant inference or prediction methods (e.g., linear regression, logistic regression, or classification and regression trees), \n",
    "including, if appropriate, feature engineering and regularization.\n",
    "4. Use cross-validation or test data as appropriate for model selection and evaluation. Make sure to\n",
    "carefully describe the methods you are using and why they are appropriate for the question to be\n",
    "answered.\n",
    "5. Summarize and interpret your results (including visualization).\n",
    "6. Provide an evaluation of your approach and discuss any limitations of the methods you used.\n",
    "7. Describe any surprising discoveries that you made and future work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning on COVID Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### States Dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data cleaning, a good starting point is to check for null and missing values and interpret what they may mean, before replacing them with any particular value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Province_State           0\n",
       "Country_Region           0\n",
       "Last_Update             83\n",
       "Lat                      5\n",
       "Long_                    5\n",
       "Confirmed                0\n",
       "Deaths                   0\n",
       "Recovered               24\n",
       "Active                   1\n",
       "FIPS                    82\n",
       "Incident_Rate            5\n",
       "People_Tested           84\n",
       "People_Hospitalized     91\n",
       "Mortality_Rate           3\n",
       "UID                      0\n",
       "ISO3                     0\n",
       "Testing_Rate            84\n",
       "Hospitalization_Rate    91\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for how many missing values are in every column\n",
    "states.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing information like People_Hospitalized with zero may not be a great idea since we cannot assume there are no people hospitalized, hence, we can replace these missing values with the mean of that country in which specific state data is missing. We can tackle People_Hospitalized, Testing_Rate, Hospitalization_Rate, People_Tested in this way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below calculates how many of the total values for each country are not missing. If a value turns out to be zero that means all data points in People_Hospitalized is missing for that country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "People_Hospitalized \n",
      " {'US': 49, 'China': 0, 'Canada': 0, 'France': 0, 'United Kingdom': 0, 'Australia': 0, 'Netherlands': 0, 'Denmark': 0}\n",
      "Hospitalization_Rate \n",
      " {'US': 49, 'China': 0, 'Canada': 0, 'France': 0, 'United Kingdom': 0, 'Australia': 0, 'Netherlands': 0, 'Denmark': 0}\n",
      "Testing_Rate \n",
      " {'US': 49, 'China': 0, 'Canada': 0, 'France': 0, 'United Kingdom': 0, 'Australia': 0, 'Netherlands': 0, 'Denmark': 0}\n",
      "People Tested \n",
      " {'US': 49, 'China': 0, 'Canada': 0, 'France': 0, 'United Kingdom': 0, 'Australia': 0, 'Netherlands': 0, 'Denmark': 0}\n",
      "Mortality Rate \n",
      " {'US': 49, 'China': 0, 'Canada': 0, 'France': 0, 'United Kingdom': 0, 'Australia': 0, 'Netherlands': 0, 'Denmark': 0}\n"
     ]
    }
   ],
   "source": [
    "countries = states['Country_Region'].value_counts().index.tolist()\n",
    "people_hospitalization_country_nulls = {}\n",
    "def usable_vals(col):\n",
    "    dic = {}\n",
    "    for country in countries:\n",
    "        dic[country] = len(states.loc[states['Country_Region'] == country,col].isnull()) - sum(states.loc[states['Country_Region'] == country,'People_Hospitalized'].isnull())\n",
    "    return dic\n",
    "People_Hospitalization_country_nulls = usable_vals('People_Hospitalized')\n",
    "Hospitalization_Rate_country_nulls = usable_vals('Hospitalization_Rate')\n",
    "print(Hospitalization_Rate_country_nulls == People_Hospitalization_country_nulls)\n",
    "print('People_Hospitalized \\n', usable_vals('People_Hospitalized'))\n",
    "print('Hospitalization_Rate \\n', usable_vals('Hospitalization_Rate'))\n",
    "print('Testing_Rate \\n', usable_vals('Testing_Rate'))\n",
    "print('People Tested \\n', usable_vals('People_Tested'))\n",
    "print('Mortality Rate \\n', usable_vals('Mortality_Rate'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the data for US contains values that will be usable so we can go ahead and replace the NaN values in the US data with the mean of that column in the US and from here note that we can only incorporate People_Hospitalized in analysis within the US. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushsehgal/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Province_State           0\n",
       "Country_Region           0\n",
       "Last_Update             83\n",
       "Lat                      5\n",
       "Long_                    5\n",
       "Confirmed                0\n",
       "Deaths                   0\n",
       "Recovered               24\n",
       "Active                   1\n",
       "FIPS                    82\n",
       "Incident_Rate            5\n",
       "People_Tested           81\n",
       "People_Hospitalized     81\n",
       "Mortality_Rate           1\n",
       "UID                      0\n",
       "ISO3                     0\n",
       "Testing_Rate            81\n",
       "Hospitalization_Rate    81\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "People_Hospitalization_US_arr = states[states['Country_Region'] == 'US']['People_Hospitalized']\n",
    "People_Hospitalization_US_arr_mean = People_Hospitalization_US_arr.mean()\n",
    "People_Hospitalization_US_arr.fillna(People_Hospitalization_US_arr_mean, inplace=True)\n",
    "states.loc[states['Country_Region'] == 'US','People_Hospitalized'] = People_Hospitalization_US_arr\n",
    "\n",
    "Hospitalization_Rate_US_arr = states[states['Country_Region'] == 'US']['Hospitalization_Rate']\n",
    "Hospitalization_Rate_US_arr_mean = Hospitalization_Rate_US_arr.mean()\n",
    "Hospitalization_Rate_US_arr.fillna(Hospitalization_Rate_US_arr_mean, inplace=True)\n",
    "states.loc[states['Country_Region'] == 'US','Hospitalization_Rate'] = Hospitalization_Rate_US_arr\n",
    "states.isnull().sum()\n",
    "\n",
    "Testing_Rate_US_arr = states[states['Country_Region'] == 'US']['Testing_Rate']\n",
    "Testing_Rate_US_arr_mean = Testing_Rate_US_arr.mean()\n",
    "Testing_Rate_US_arr.fillna(Testing_Rate_US_arr_mean, inplace=True)\n",
    "states.loc[states['Country_Region'] == 'US','Testing_Rate'] = Testing_Rate_US_arr\n",
    "states.isnull().sum()\n",
    "\n",
    "People_Tested_US_arr = states[states['Country_Region'] == 'US']['People_Tested']\n",
    "People_Tested_US_arr_mean = People_Tested_US_arr.mean()\n",
    "People_Tested_US_arr.fillna(People_Tested_US_arr_mean, inplace=True)\n",
    "states.loc[states['Country_Region'] == 'US','People_Tested'] = People_Tested_US_arr\n",
    "states.isnull().sum()\n",
    "\n",
    "Mortality_Rate_US_arr = states[states['Country_Region'] == 'US']['Mortality_Rate']\n",
    "Mortality_Rate_US_arr_mean = Mortality_Rate_US_arr.mean()\n",
    "Mortality_Rate_US_arr.fillna(Mortality_Rate_US_arr_mean, inplace=True)\n",
    "states.loc[states['Country_Region'] == 'US','Mortality_Rate'] = Mortality_Rate_US_arr\n",
    "states.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still an uncovered NaN value in Mortality_Rate so we can explore that item, which happens to exist in position 115 from inspection. That item is weirdly a float object type, so we can manually replace this element with the mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushsehgal/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:6746: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Province_State           0\n",
       "Country_Region           0\n",
       "Last_Update             83\n",
       "Lat                      5\n",
       "Long_                    5\n",
       "Confirmed                0\n",
       "Deaths                   0\n",
       "Recovered               24\n",
       "Active                   1\n",
       "FIPS                    82\n",
       "Incident_Rate            5\n",
       "People_Tested           81\n",
       "People_Hospitalized     81\n",
       "Mortality_Rate           1\n",
       "UID                      0\n",
       "ISO3                     0\n",
       "Testing_Rate            81\n",
       "Hospitalization_Rate    81\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weird_nan = states['Mortality_Rate'].values[115]\n",
    "print(type(weird_nan))\n",
    "Mortality_Rate_US_arr.replace(to_replace=weird_nan, value=Mortality_Rate_US_arr_mean, inplace=True)\n",
    "states.loc[states['Country_Region'] == 'US','Mortality_Rate'] = Mortality_Rate_US_arr\n",
    "states.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cases DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases.isnull().sum().values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
